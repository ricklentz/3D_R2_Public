{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Public 1.5B OpenGPT-2 GPU Inference ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricklentz/3D_R2_Public/blob/master/1_5B_OpenGPT_2_GPU_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDKbiVNRJSWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cd47f0d0-cc80-4b76-a9f9-6ec2f96e36ef"
      },
      "source": [
        "!git clone https://github.com/rowanz/grover.git\n",
        "%cd /content/grover"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'grover'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 76 (delta 25), reused 66 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n",
            "/content/grover\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0H-Gkg0XV-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "cc610887-9e5c-46da-e9b1-d0bc52c2b1d5"
      },
      "source": [
        "!python3 -m pip install regex jsonlines \n",
        "!python3 -m pip install -U tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 1.9MB/s \n",
            "\u001b[?25hCollecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609236 sha256=d85aba2bbc9341be7ccd3f929660b892e2378d4e932852d23a3fe589052f5c7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, jsonlines\n",
            "Successfully installed jsonlines-1.2.0 regex-2019.8.19\n",
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/83/06029af22fe06b8a7be013aeae5e104b3ed26867e5d4ca91408b30aa602e/tqdm-4.34.0-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.4MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed tqdm-4.34.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip52YU9X5BwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b9a7c79b-9913-4ee1-b479-35dc72ba0844"
      },
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "import os  \n",
        "import io\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "model_type = 'mega'\n",
        "model_path = '/content/grover/models'\n",
        "model_dir = os.path.join(model_path, model_type)\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "NUMBER = 800000\n",
        "MODEL = \"grover_mega_owt_fix\"\n",
        "\n",
        "local_file_ids = ['1t1B5JfjolytwSSUAGOZCnstVlaL2Bg25', '1kojGap2kXzkJBWtwIZtOXgeV3IWnNMtO', '1FITtxBwJsagKfaLz9tgsguHbbdMCyeQw']\n",
        "local_filenames = ['.data-00000-of-00001', '.index', '.meta']\n",
        "for ext, id_ in zip(local_filenames, local_file_ids):\n",
        "    ext = str(NUMBER) + ext\n",
        "    filename = '%s/%s/model.ckpt.%s' % (model_path, model_type, ext) \n",
        "    \n",
        "    request = drive_service.files().get_media(fileId=id_)\n",
        "    with open(filename, 'wb') as f:\n",
        "      downloader = MediaIoBaseDownload(f, request, chunksize=100*1024*1024)\n",
        "      done = False\n",
        "      pbar = tqdm(total=100, desc='%s' % ext)\n",
        "      progress = 0\n",
        "      while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "        new_progress = int(status.progress() * 100)\n",
        "        pbar.update(new_progress - progress)\n",
        "        progress = new_progress\n",
        "\n",
        "      pbar.close()\n",
        "      print('Downloaded %s' % filename)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eb5eb09e4414cc594b83b2f5ca52541",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='800000.data-00000-of-00001', style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloaded /content/grover/models/mega/model.ckpt.800000.data-00000-of-00001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f2e8784ad1c477492a2e4bcfbd49444",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='800000.index', style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloaded /content/grover/models/mega/model.ckpt.800000.index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "797388b64bbb492da5676aa9eecee5f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='800000.meta', style=ProgressStyle(description_width='initial'…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloaded /content/grover/models/mega/model.ckpt.800000.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmQXE6pUhabg",
        "colab_type": "code",
        "outputId": "469ca4f7-312b-46f9-8e3b-358ecce32d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/grover"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/grover\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGQI4BECpHiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sample/encoder.py', 'w') as f:\n",
        "  f.write(\"\"\"\\n\\\"\\\"\\\"Byte pair encoding utilities\\n\\nSome functions are adapted from OpenAI but with modifications\\n\\nhttps://github.com/openai/gpt-2\\n\\\"\\\"\\\"\\n\\nimport os\\nimport json\\nimport regex as re\\nfrom functools import lru_cache\\nimport tensorflow as tf\\nimport random\\nimport numpy as np\\n\\n\\n@lru_cache()\\ndef bytes_to_unicode():\\n    \\\"\\\"\\\"\\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\\n    The reversible bpe codes work on unicode strings.\\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\\n    \\\"\\\"\\\"\\n    bs = list(range(ord(\"!\"), ord(\"~\") + 1)) + list(range(ord(\"¡\"), ord(\"¬\") + 1)) + list(range(ord(\"®\"), ord(\"ÿ\") + 1))\\n    cs = bs[:]\\n    n = 0\\n    for b in range(2 ** 8):\\n        if b not in bs:\\n            bs.append(b)\\n            cs.append(2 ** 8 + n)\\n            n += 1\\n    cs = [chr(n) for n in cs]\\n    return dict(zip(bs, cs))\\n\\n\\ndef get_pairs(word):\\n    \\\"\\\"\\\"Return set of symbol pairs in a word.\\n\\n    Word is represented as tuple of symbols (symbols being variable-length strings).\\n    \\\"\\\"\\\"\\n    pairs = set()\\n    prev_char = word[0]\\n    for char in word[1:]:\\n        pairs.add((prev_char, char))\\n        prev_char = char\\n    return pairs\\n\\n\\nclass Encoder:\\n    def __init__(self, encoder, bpe_merges, errors='replace'):\\n        # self.encoder = {k: v + 1 for k, v in encoder.items()}\\n        # self.encoder['<|padding|>'] = 0\\n        # self.padding = 0\\n        #\\n        # del self.encoder['<|endoftext|>']\\n        #\\n        # for special_token_type in ['domain', 'date', 'authors', 'title', 'article', 'summary']:\\n        #     setattr(self, f'begin_{special_token_type}', len(self.encoder))\\n        #     self.encoder[f'<|begin{special_token_type}|>'] = len(self.encoder)\\n        #\\n        #     setattr(self, f'end_{special_token_type}', len(self.encoder))\\n        #     self.encoder[f'<|endof{special_token_type}|>'] = len(self.encoder)\\n        #\\n        # # This will be used if we want to combine short articles.\\n        # self.reset_context = len(self.encoder)\\n        # self.encoder['<|resetcontext|>'] = len(self.encoder)\\n\\n        self.encoder = encoder\\n        self.endoftext = self.encoder['<|endoftext|>']\\n\\n        ################################## END OF SPECIAL TOKENS TO ADD\\n\\n        self.decoder = {v: k for k, v in self.encoder.items()}\\n        self.errors = errors  # how to handle errors in decoding\\n        self.byte_encoder = bytes_to_unicode()\\n        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\\n        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))\\n        self.cache = {}\\n\\n        # Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions\\n        self.pat = re.compile(r\\\"\\\"\\\"'s|'t|'re|'ve|'m|'ll|'d| ?\\\\p{L}+| ?\\\\p{N}+| ?[^\\\\s\\\\p{L}\\\\p{N}]+|\\\\s+(?!\\\\S)|\\\\s+\\\"\\\"\\\")\\n\\n    def bpe(self, token):\\n        if token in self.cache:\\n            return self.cache[token]\\n        word = tuple(token)\\n        pairs = get_pairs(word)\\n\\n        if not pairs:\\n            return token\\n\\n        while True:\\n            bigram = min(pairs, key=lambda pair: self.bpe_ranks.get(pair, float('inf')))\\n            if bigram not in self.bpe_ranks:\\n                break\\n            first, second = bigram\\n            new_word = []\\n            i = 0\\n            while i < len(word):\\n                try:\\n                    j = word.index(first, i)\\n                    new_word.extend(word[i:j])\\n                    i = j\\n                except:\\n                    new_word.extend(word[i:])\\n                    break\\n\\n                if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\\n                    new_word.append(first + second)\\n                    i += 2\\n                else:\\n                    new_word.append(word[i])\\n                    i += 1\\n            new_word = tuple(new_word)\\n            word = new_word\\n            if len(word) == 1:\\n                break\\n            else:\\n                pairs = get_pairs(word)\\n        word = ' '.join(word)\\n        self.cache[token] = word\\n        return word\\n\\n    def encode(self, text):\\n        bpe_tokens = []\\n        for token in re.findall(self.pat, text):\\n            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\\n            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\\n        return bpe_tokens\\n\\n    def decode(self, tokens):\\n        text = ''.join([self.decoder[token] for token in tokens])\\n        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=self.errors)\\n        return text\\n\\n    def __len__(self):\\n        return len(self.encoder)\\n\\n    @property\\n    def special_tokens_onehot(self):\\n        \\\"\\\"\\\" Return the IDs of all special tokens\\\"\\\"\\\"\\n        return [(self.decoder[i].startswith('<|') and self.decoder[i].endswith('|>')) for i in range(len(self))]\\n\\n\\ndef get_encoder():\\n    directory_name = os.path.dirname(__file__)\\n    with open(os.path.join(directory_name, 'encoder.json'), 'r') as f:\\n        encoder = json.load(f)\\n    with open(os.path.join(directory_name, 'vocab.bpe'), 'r', encoding=\"utf-8\") as f:\\n        bpe_data = f.read()\\n    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\\\n')[1:-1]]\\n    return Encoder(\\n        encoder=encoder,\\n        bpe_merges=bpe_merges,\\n    )\\n\\n\\n##############################################################\\n# TURN SOMETHING INTO THE RIGHT FORMAT FOR AN EXAMPLE\\n##############################################################\\ndef _tokenize_article_pieces(encoder, item):\\n    \\\"\\\"\\\"\\n    Turn the article into tokens\\n    NOTE: in hindsight I kinda messed up here because the first token is always represented as a BPE continuation\\n    rather than an initial token in its own right. whoops....\\n\\n    :param item: Contains things that need to be tokenized\\n\\n\\n    fields are ['domain', 'date', 'authors', 'title', 'article', 'summary']\\n    :return: dict\\n    \\\"\\\"\\\"\\n    # article_pieces = {\\n    #     'article': [encoder.begin_article] + encoder.encode(item['text']) + [encoder.end_article],\\n    #     'domain': [encoder.begin_domain] + encoder.encode(item['domain']) + [encoder.end_domain],\\n    #     'title': [encoder.begin_title] + encoder.encode(item['title']) + [encoder.end_title],\\n    # }\\n    # # 4/6: Attach the summary too, why the hell not\\n    # if item['summary'] and len(item['summary']) > 50:\\n    #     article_pieces['summary'] = [encoder.begin_summary] + encoder.encode(item['summary']) + [encoder.end_summary]\\n    #\\n    # # 5/6: date\\n    # date_split = item['publish_date'].split('-')\\n    # assert len(date_split) == 3\\n    # assert date_split[0].isdigit()\\n    #\\n    # date_txt = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\\n    #             'August', 'September', 'October', 'November', 'December'][int(date_split[0]) - 1] + ' {}, {}'.format(\\n    #     date_split[1], date_split[2])\\n    # article_pieces['date'] = [encoder.begin_date] + encoder.encode(date_txt) + [encoder.end_date]\\n    #\\n    # # 6/6: authors\\n    # authors = ', '.join(item['authors'])\\n    # if len(authors) > 5:\\n    #     article_pieces['authors'] = [encoder.begin_authors] + encoder.encode(authors) + [encoder.end_authors]\\n    return encoder.encode(item) + [encoder.endoftext]\\n\\n\\ndef _cut_tokens_to_add_stuff(tokens, stuff_to_add, desired_size, padding_token):\\n    \\\"\\\"\\\"\\n    The idea behind this function is to take away tokens from `tokens' such that tokens[:LENGTH] + stuff_to_add becomes\\n    exactly at the right size (desired_size).\\n\\n    :param tokens:\\n    :param stuff_to_add:\\n    :param desired_size:\\n    :return:\\n    \\\"\\\"\\\"\\n    if len(tokens) >= desired_size:\\n        return tokens\\n\\n    # no way we can add this stuff\\n    if len(stuff_to_add) >= desired_size:\\n        return tokens\\n\\n    if (len(tokens) + len(stuff_to_add)) <= desired_size:\\n        return tokens + stuff_to_add\\n\\n    # Otherwise we'll have to actually cut\\n    tokens = tokens[:(desired_size - len(stuff_to_add) - 1)]\\n    tokens.append(padding_token)\\n    tokens.extend(stuff_to_add)\\n    return tokens\\n\\n\\ndef tokenize_for_grover_training(encoder, item, desired_size=1024, unconditional_prob=0.35, metadata_dropout_prob=0.1,\\n                                 cut_prob=0.2):\\n    \\\"\\\"\\\"\\n    Not only will we tokenize an item with a BPE encoder, but we'll also put it in a nice format for language modeling.\\n    The goal is to MINIMIZE PADDING. If we don't fill up the desired size of 1024 tokens then we're wasting compute.\\n\\n    The canonical order is\\n\\n    DOMAIN DATE AUTHORS TITLE ARTICLE SUMMARY\\n\\n\\n    :param encoder:\\n    :param item: Contains things like\\n          {\"url\": \"https://www.advocate.com/node/1010911\",\\n          \"timestamp\": \"20180118211607\",\\n           \"url_used\": \"https://web.archive.org/web/20180118211607id_/https://www.advocate.com/node/1010911\",\\n           \"domain\": \"advocate.com\",\\n           \"title\": \"Report: One-Third of Trump's Judicial Picks Are Anti-LGBT\",\\n           \"text\": ....\\n           \"summary\": ....\\n           \"authors\": list\\n           \"publish_date\": ...\\n           }\\n    :param desired_size: the goal for how long the span will be\\n    :param unconditional_prob: The probability that we will generate JUST THE TEXT first.\\n    :param metadata_dropout_prob: The probability that we will drop out each item of metadata\\n    :param cut_prob: The probability that, if we're already over the desired size, we'll cut the article and start\\n                    predicting metadata before the desired_size window ends.\\n    :return:\\n    \\\"\\\"\\\"\\n    # Get all the bits and pieces\\n    tokens = _tokenize_article_pieces(encoder, item)\\n    # canonical_metadata_order = ['domain', 'date', 'authors', 'title']\\n    #\\n    # # unconditional_prob is probability we only generate the text first, without any metadata\\n    # switch = random.random()\\n    # if switch < unconditional_prob:\\n    #     assignments = {'article': 'a'}\\n    #     chunk_a = article_pieces.pop('article')\\n    #     chunk_b = []\\n    #     for x in canonical_metadata_order + ['summary']:\\n    #         if random.random() > metadata_dropout_prob:\\n    #             chunk_b.extend(article_pieces.pop(x, []))\\n    #             assignments[x] = 'b'\\n    # elif switch < 0.5:\\n    #     # Put everything in chunk_a, without dropout\\n    #     assignments = {}\\n    #     chunk_a = []\\n    #     chunk_b = []\\n    #     for x in canonical_metadata_order + ['article', 'summary']:\\n    #         chunk_a.extend(article_pieces.pop(x, []))\\n    #         assignments[x] = 'a'\\n    # else:\\n    #     assignments = {}\\n    #     chunk_a = []\\n    #     chunk_b = []\\n    #     for k in canonical_metadata_order + ['article', 'summary']:\\n    #         if random.random() < metadata_dropout_prob and k not in ('article', 'title'):\\n    #             pass\\n    #         elif random.random() < 0.5:\\n    #             if k != 'summary':\\n    #                 chunk_a.extend(article_pieces.pop(k, []))\\n    #                 assignments[k] = 'a'\\n    #         else:\\n    #             chunk_b.extend(article_pieces.pop(k, []))\\n    #             assignments[k] = 'b'\\n    #\\n    # if (len(chunk_a) + len(chunk_b)) <= desired_size:\\n    #     return chunk_a + chunk_b\\n    #\\n    # if (assignments.get('article', '') == 'a') and (len(chunk_b) > 0) and (random.random() < cut_prob):\\n    #     return _cut_tokens_to_add_stuff(chunk_a, chunk_b, desired_size, encoder.padding)\\n    #\\n    # tokens = chunk_a + chunk_b\\n\\n    return tokens\\n\\n\\ndef detokenize(encoder, tokens):\\n    return encoder.decode(tokens)\\n\\n\\n#######################################\\n\\ndef create_int_feature(values):\\n    feature = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\\n    return feature\\n\\n\\ndef sliding_window(article, max_seq_length):\\n    \\\"\\\"\\\"\\n    Randomly sample some spans. It's a simple approximation of sliding window\\n    :param tokens:\\n    :param max_seq_length:\\n    :return:\\n    \\\"\\\"\\\"\\n    # if it's shorter, no need for this\\n    if len(article['input_ids']) <= max_seq_length:\\n        amount_to_pad = max_seq_length - len(article['input_ids'])\\n        yield article\\n        return\\n\\n    num_spans = len(article['input_ids']) - max_seq_length + 1\\n    weights = np.ones(num_spans, dtype=np.float32)\\n    # weights[0] = max_seq_length\\n    weights /= weights.sum()\\n\\n    num_to_yield = int(0.5 + len(article['input_ids']) / max_seq_length)\\n    starts = np.random.choice(num_spans, size=num_to_yield, replace=False, p=weights)\\n\\n    input_ids = article.pop('input_ids')\\n    for i in starts.tolist():\\n        article['input_ids'] = input_ids[i:(i + max_seq_length)]\\n        yield article\\n\\n# def sliding_window(article, max_seq_length, pad_token):\\n#     \\\"\\\"\\\"\\n#     Randomly sample some spans. It's a simple approximation of sliding window\\n#     :param tokens:\\n#     :param max_seq_length:\\n#     :return:\\n#     \\\"\\\"\\\"\\n#     # if it's shorter, no need for this\\n#     if len(article['input_ids']) <= max_seq_length:\\n#         amount_to_pad = max_seq_length - len(article['input_ids'])\\n#         article['input_ids'].extend([pad_token] * amount_to_pad)\\n#         yield article\\n#         return\\n#\\n#     num_spans = len(article['input_ids']) - max_seq_length + 1\\n#     weights = np.ones(num_spans, dtype=np.float32)\\n#     # weights[0] = max_seq_length\\n#     weights /= weights.sum()\\n#\\n#     num_to_yield = int(0.5 + len(article['input_ids']) / max_seq_length)\\n#     starts = np.random.choice(num_spans, size=num_to_yield, replace=False, p=weights)\\n#\\n#     input_ids = article.pop('input_ids')\\n#     for i in starts.tolist():\\n#         article['input_ids'] = input_ids[i:(i + max_seq_length)]\\n#         yield article\\n\\n\\ndef format_context(encoder, news_article, target):\\n    \\\"\\\"\\\"\\n    Generates a news article given some partial information\\n    :param news_article: Contains context\\n    :param target: What we want to get an answer for.\\n    :return:\\n    \\\"\\\"\\\"\\n    canonical_metadata_order = ['domain', 'date', 'authors', 'title', 'article']\\n    tokens = []\\n    for metadata_category in canonical_metadata_order:\\n        metadata = news_article.get(metadata_category, '').strip()\\n\\n        # This MIGHT BE needed because I think during training time we never saw empty articles\\n        # if metadata or ((metadata_category == 'article') and target != 'article'):\\n        if (metadata_category == 'article') and (target != 'article'):\\n            metadata = news_article.get('title', '')  # Just copy from the title maybe?\\n\\n        if metadata:\\n            tokens.append(encoder.__dict__[f'begin_{metadata_category}'])\\n            tokens.extend(encoder.encode(metadata))\\n            tokens.append(encoder.__dict__[f'end_{metadata_category}'])\\n\\n    assert target in (canonical_metadata_order + ['summary'])\\n    tokens.append(encoder.__dict__[f'begin_{target}'])\\n    return tokens\\n\\ndef extract_generated_target(output_tokens, encoder, target):\\n    \\\"\\\"\\\"\\n    Given some tokens that were generated, extract the target\\n    :param output_tokens: [num_tokens] thing that was generated\\n    :param encoder: how they were encoded\\n    :param target: the piece of metadata we wanted to generate!\\n    :return:\\n    \\\"\\\"\\\"\\n    # Filter out first instance of start token\\n    assert output_tokens.ndim == 1\\n\\n    start_ind = 0\\n    end_ind = output_tokens.shape[0]\\n\\n    return {\\n        'extraction': encoder.decode(output_tokens[start_ind:end_ind]),\\n        'start_ind': start_ind,\\n        'end_ind': end_ind,\\n    }\\n\\n# def extract_generated_target(output_tokens, encoder, target):\\n#     \\\"\\\"\\\"\\n#     Given some tokens that were generated, extract the target\\n#     :param output_tokens: [num_tokens] thing that was generated\\n#     :param encoder: how they were encoded\\n#     :param target: the piece of metadata we wanted to generate!\\n#     :return:\\n#     \\\"\\\"\\\"\\n#     # Filter out first instance of start token\\n#     assert output_tokens.ndim == 1\\n#\\n#     start_tokens = output_tokens == encoder.__dict__[f'begin_{target}']\\n#     if np.any(start_tokens):\\n#         start_ind = np.argmax(start_tokens) + 1\\n#     else:\\n#         start_ind = 0\\n#\\n#     end_tokens = output_tokens == encoder.__dict__[f'end_{target}']\\n#     if np.any(end_tokens):\\n#         end_ind = np.argmax(end_tokens)\\n#     else:\\n#         end_ind = output_tokens.shape[0]\\n#\\n#     return {\\n#         'extraction': encoder.decode(output_tokens[start_ind:end_ind]),\\n#         'start_ind': start_ind,\\n#         'end_ind': end_ind,\\n#     }\\n\\n\\nif __name__ == '__main__':\\n    encoder = get_encoder()\\n    print(\"VOCAB SIZE IS {}\".format(len(encoder.encoder)))\\n\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZZlKUxYnFFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Supports repetitions with -samples <number>\n",
        "with open('sample/contextual_generate_cli.py', 'w') as f:\n",
        "  f.write(\"\"\"\\nimport tensorflow as tf\\nimport numpy as np\\nimport sys\\nimport json\\nimport sys\\n\\nsys.path.append('../')\\nfrom lm.modeling import GroverModel, GroverConfig, _top_p_sample, sample\\nfrom sample.encoder import get_encoder, format_context, _tokenize_article_pieces, extract_generated_target\\nfrom tqdm import tqdm\\n\\nimport argparse\\n\\nparser = argparse.ArgumentParser(description='Contextual generation (aka given some metadata we will generate articles')\\nparser.add_argument(\\n    '-metadata_fn',\\n    dest='metadata_fn',\\n    type=str,\\n    help='Path to a JSONL containing metadata',\\n)\\nparser.add_argument(\\n    '-out_fn',\\n    dest='out_fn',\\n    type=str,\\n    help='Out jsonl, which will contain the completed jsons',\\n)\\nparser.add_argument(\\n    '-input',\\n    dest='input',\\n    type=str,\\n    help='Text to complete',\\n)\\nparser.add_argument(\\n    '-model_config_fn',\\n    dest='model_config_fn',\\n    default='../lm/configs/base.json',\\n    type=str,\\n    help='Configuration JSON for the model',\\n)\\nparser.add_argument(\\n    '-model_ckpt',\\n    dest='model_ckpt',\\n    default='../models/base/model.ckpt',\\n    type=str,\\n    help='checkpoint file for the model',\\n)\\nparser.add_argument(\\n    '-target',\\n    dest='target',\\n    default='article',\\n    type=str,\\n    help='What to generate for each item in metadata_fn. can be article (body), title, etc.',\\n)\\nparser.add_argument(\\n    '-batch_size',\\n    dest='batch_size',\\n    default=1,\\n    type=int,\\n    help='How many things to generate per context. will split into chunks if need be',\\n)\\nparser.add_argument(\\n    '-num_folds',\\n    dest='num_folds',\\n    default=1,\\n    type=int,\\n    help='Number of folds. useful if we want to split up a big file into multiple jobs.',\\n)\\nparser.add_argument(\\n    '-fold',\\n    dest='fold',\\n    default=0,\\n    type=int,\\n    help='which fold we are on. useful if we want to split up a big file into multiple jobs.'\\n)\\nparser.add_argument(\\n    '-max_batch_size',\\n    dest='max_batch_size',\\n    default=None,\\n    type=int,\\n    help='max batch size. You can leave this out and we will infer one based on the number of hidden layers',\\n)\\nparser.add_argument(\\n    '-top_p',\\n    dest='top_p',\\n    default=0.95,\\n    type=float,\\n    help='p to use for top p sampling. if this isn\\\\'t none, use this for everthing'\\n)\\nparser.add_argument(\\n    '-samples',\\n    dest='samples',\\n    default=1,\\n    type=int,\\n    help='num_samples',\\n)\\n\\nargs = parser.parse_args()\\n\\nencoder = get_encoder()\\nnews_config = GroverConfig.from_json_file(args.model_config_fn)\\n\\n# We might have to split the batch into multiple chunks if the batch size is too large\\ndefault_mbs = {12: 32, 24: 16, 48: 3}\\nmax_batch_size = args.max_batch_size if args.max_batch_size is not None else default_mbs[news_config.num_hidden_layers]\\n\\n# factorize args.batch_size = (num_chunks * batch_size_per_chunk) s.t. batch_size_per_chunk < max_batch_size\\nnum_chunks = int(np.ceil(args.batch_size / max_batch_size))\\nbatch_size_per_chunk = int(np.ceil(args.batch_size / num_chunks))\\nprint(\"\\\\n~~\\\\nbatch size={}, max batch size={}, num chunks={}, batch size per chunk={}\\\\n~~\\\\n\".format(\\n    args.batch_size, max_batch_size, num_chunks, batch_size_per_chunk), flush=True)\\n\\n# This controls the top p for each generation.\\ntop_p = np.ones((num_chunks, batch_size_per_chunk), dtype=np.float32) * args.top_p\\n\\n# with open(args.metadata_fn, 'r') as f:\\n#     articles = [json.loads(l) for i, l in enumerate(f) if i % args.num_folds == args.fold]\\n\\ntf_config = tf.ConfigProto(allow_soft_placement=True)\\n\\nwith tf.Session(config=tf_config, graph=tf.Graph()) as sess:\\n    initial_context = tf.placeholder(tf.int32, [batch_size_per_chunk, None])\\n    p_for_topp = tf.placeholder(tf.float32, [batch_size_per_chunk])\\n    eos_token = tf.placeholder(tf.int32, [])\\n    tokens, probs = sample(news_config=news_config, initial_context=initial_context,\\n                           eos_token=eos_token, ignore_ids=None, p_for_topp=p_for_topp,\\n                           do_topk=False)\\n\\n    saver = tf.train.Saver()\\n    saver.restore(sess, args.model_ckpt)\\n    print('Loaded model.')\\n    text = input()\\n    while text != \"\":\\n        for i in range(args.samples):\\n            print(\"Sample,\", i + 1, \" of \", args.samples)\\n            # Let's go!\\n            encoded = _tokenize_article_pieces(encoder, text)\\n            context_formatted = []\\n            # for key in ['domain', 'date', 'authors', 'title', 'article']:\\n            #     if key != args.target:\\n            #         context_formatted.extend(article_pieces.pop(key, []))\\n            # context_formatted.append(encoder.__dict__['begin_{}'.format(args.target)])\\n            context_formatted.extend(encoded[:-1])\\n            # Format context end\\n\\n            # Indices we definitely DONT WANT TO PREDICT\\n            ignore_ids_np = np.array(encoder.special_tokens_onehot)\\n            ignore_ids_np[encoder.endoftext] = 0\\n\\n            gens = []\\n            gens_raw = []\\n            gen_probs = []\\n\\n            # article['top_ps'] = top_p.reshape(-1).tolist()\\n            for chunk_i in range(num_chunks):\\n                tokens_out, probs_out = sess.run([tokens, probs],\\n                                                 feed_dict={initial_context: [context_formatted] * batch_size_per_chunk,\\n                                                            eos_token: 60000,\\n                                                            p_for_topp: top_p[chunk_i]})\\n\\n                for t_i, p_i in zip(tokens_out, probs_out):\\n                    extraction = extract_generated_target(output_tokens=t_i, encoder=encoder, target=args.target)\\n                    gens.append(extraction['extraction'])\\n\\n            # article['gens_{}'.format(args.target)] = gens\\n            # article['gensraw_{}'.format(args.target)] = gens_raw\\n            # article['probs_{}'.format(args.target)] = gen_probs\\n\\n            # these were in there for whatever reason...\\n            # article.pop('input_ids_conditional', None)\\n            # article.pop('input_ids_unconditional', None)\\n            # f_out.write(json.dumps(article) + '\\\\n')\\n            print(gens[0])\\n        text = input()\\n\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZw6tt7qCNYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Supports repetitions with -samples <number>\n",
        "# This version supports multi line input, but colab doesn't support EOF from the stdin interface so there is no way to actaully press enter other than echoing input.\n",
        "with open('sample/contextual_generate_cli_multiline.py', 'w') as f:\n",
        "  f.write(\"\"\"\\n\\n\\nimport tensorflow as tf\\nimport numpy as np\\nimport sys\\nimport json\\nimport sys\\n\\nsys.path.append('../')\\nfrom lm.modeling import GroverModel, GroverConfig, _top_p_sample, sample\\nfrom sample.encoder import get_encoder, format_context, _tokenize_article_pieces, extract_generated_target\\nfrom tqdm import tqdm\\n\\nimport argparse\\n\\nparser = argparse.ArgumentParser(description='Contextual generation (aka given some metadata we will generate articles')\\nparser.add_argument(\\n    '-metadata_fn',\\n    dest='metadata_fn',\\n    type=str,\\n    help='Path to a JSONL containing metadata',\\n)\\nparser.add_argument(\\n    '-out_fn',\\n    dest='out_fn',\\n    type=str,\\n    help='Out jsonl, which will contain the completed jsons',\\n)\\nparser.add_argument(\\n    '-input',\\n    dest='input',\\n    type=str,\\n    help='Text to complete',\\n)\\nparser.add_argument(\\n    '-model_config_fn',\\n    dest='model_config_fn',\\n    default='../lm/configs/base.json',\\n    type=str,\\n    help='Configuration JSON for the model',\\n)\\nparser.add_argument(\\n    '-model_ckpt',\\n    dest='model_ckpt',\\n    default='../models/base/model.ckpt',\\n    type=str,\\n    help='checkpoint file for the model',\\n)\\nparser.add_argument(\\n    '-target',\\n    dest='target',\\n    default='article',\\n    type=str,\\n    help='What to generate for each item in metadata_fn. can be article (body), title, etc.',\\n)\\nparser.add_argument(\\n    '-batch_size',\\n    dest='batch_size',\\n    default=1,\\n    type=int,\\n    help='How many things to generate per context. will split into chunks if need be',\\n)\\nparser.add_argument(\\n    '-num_folds',\\n    dest='num_folds',\\n    default=1,\\n    type=int,\\n    help='Number of folds. useful if we want to split up a big file into multiple jobs.',\\n)\\nparser.add_argument(\\n    '-fold',\\n    dest='fold',\\n    default=0,\\n    type=int,\\n    help='which fold we are on. useful if we want to split up a big file into multiple jobs.'\\n)\\nparser.add_argument(\\n    '-max_batch_size',\\n    dest='max_batch_size',\\n    default=None,\\n    type=int,\\n    help='max batch size. You can leave this out and we will infer one based on the number of hidden layers',\\n)\\nparser.add_argument(\\n    '-top_p',\\n    dest='top_p',\\n    default=0.95,\\n    type=float,\\n    help='p to use for top p sampling. if this isn\\\\'t none, use this for everthing'\\n)\\nparser.add_argument(\\n    '-samples',\\n    dest='samples',\\n    default=1,\\n    type=int,\\n    help='num_samples',\\n)\\n\\nargs = parser.parse_args()\\n\\nencoder = get_encoder()\\nnews_config = GroverConfig.from_json_file(args.model_config_fn)\\n\\n# We might have to split the batch into multiple chunks if the batch size is too large\\ndefault_mbs = {12: 32, 24: 16, 48: 3}\\nmax_batch_size = args.max_batch_size if args.max_batch_size is not None else default_mbs[news_config.num_hidden_layers]\\n\\n# factorize args.batch_size = (num_chunks * batch_size_per_chunk) s.t. batch_size_per_chunk < max_batch_size\\nnum_chunks = int(np.ceil(args.batch_size / max_batch_size))\\nbatch_size_per_chunk = int(np.ceil(args.batch_size / num_chunks))\\nprint(\"\\\\n~~\\\\nbatch size={}, max batch size={}, num chunks={}, batch size per chunk={}\\\\n~~\\\\n\".format(\\n    args.batch_size, max_batch_size, num_chunks, batch_size_per_chunk), flush=True)\\n\\n# This controls the top p for each generation.\\ntop_p = np.ones((num_chunks, batch_size_per_chunk), dtype=np.float32) * args.top_p\\n\\n# with open(args.metadata_fn, 'r') as f:\\n#     articles = [json.loads(l) for i, l in enumerate(f) if i % args.num_folds == args.fold]\\n\\ntf_config = tf.ConfigProto(allow_soft_placement=True)\\n\\nwith tf.Session(config=tf_config, graph=tf.Graph()) as sess:\\n    initial_context = tf.placeholder(tf.int32, [batch_size_per_chunk, None])\\n    p_for_topp = tf.placeholder(tf.float32, [batch_size_per_chunk])\\n    eos_token = tf.placeholder(tf.int32, [])\\n    tokens, probs = sample(news_config=news_config, initial_context=initial_context,\\n                           eos_token=eos_token, ignore_ids=None, p_for_topp=p_for_topp,\\n                           do_topk=False)\\n\\n    saver = tf.train.Saver()\\n    saver.restore(sess, args.model_ckpt)\\n    print('Loaded model.')\\n    text = \"\".join(sys.stdin.readlines())\\n    for i in range(args.samples):\\n        print(\"Sample,\", i + 1, \" of \", args.samples)\\n        # Let's go!\\n        encoded = _tokenize_article_pieces(encoder, text)\\n        context_formatted = []\\n            \\n        context_formatted.extend(encoded[:-1])\\n        # Format context end\\n\\n        # Indices we definitely DONT WANT TO PREDICT\\n        ignore_ids_np = np.array(encoder.special_tokens_onehot)\\n        ignore_ids_np[encoder.endoftext] = 0\\n\\n        gens = []\\n        gens_raw = []\\n        gen_probs = []\\n\\n        # article['top_ps'] = top_p.reshape(-1).tolist()\\n        for chunk_i in range(num_chunks):\\n            tokens_out, probs_out = sess.run([tokens, probs],\\n                                             feed_dict={initial_context: [context_formatted] * batch_size_per_chunk,\\n                                                            eos_token: 60000,\\n                                                            p_for_topp: top_p[chunk_i]})\\n\\n            for t_i, p_i in zip(tokens_out, probs_out):\\n                extraction = extract_generated_target(output_tokens=t_i, encoder=encoder, target=args.target)\\n                gens.append(extraction['extraction'])\\n        print(gens[0])\\n\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50jDXTRGTTgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "133dfc4d-8677-46da-819e-80789ae072ee"
      },
      "source": [
        "#THis option lets you type from colab, but you can't enter new lines\n",
        "!PYTHONPATH=$(pwd) python3 sample/contextual_generate_cli.py -model_config_fn lm/configs/mega.json -model_ckpt models/mega/model.ckpt.800000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0823 12:51:54.145685 140496308524928 deprecation_wrapper.py:119] From /content/grover/lm/optimization_adafactor.py:88: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0823 12:51:54.249033 140496308524928 deprecation_wrapper.py:119] From /content/grover/lm/modeling.py:87: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "\n",
            "~~\n",
            "batch size=1, max batch size=3, num chunks=1, batch size per chunk=1\n",
            "~~\n",
            "\n",
            "W0823 12:51:54.249846 140496308524928 deprecation_wrapper.py:119] From sample/contextual_generate_cli.py:119: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0823 12:51:54.250112 140496308524928 deprecation_wrapper.py:119] From sample/contextual_generate_cli.py:121: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-08-23 12:51:54.265239: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-23 12:51:54.265503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30032c0 executing computations on platform Host. Devices:\n",
            "2019-08-23 12:51:54.265537: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-23 12:51:54.278442: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-23 12:51:54.374147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:51:54.374677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3003d40 executing computations on platform CUDA. Devices:\n",
            "2019-08-23 12:51:54.374709: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-23 12:51:54.375406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:51:54.375791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-23 12:51:54.382345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-23 12:51:54.390559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-23 12:51:54.395129: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-23 12:51:54.403349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-23 12:51:54.413323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-23 12:51:54.420820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-23 12:51:54.437426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-23 12:51:54.437527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:51:54.438070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:51:54.438509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-23 12:51:54.438573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-23 12:51:54.439691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-23 12:51:54.439725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-23 12:51:54.439742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-23 12:51:54.440123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:51:54.440531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:51:54.440917: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-23 12:51:54.440970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0823 12:51:54.443311 140496308524928 deprecation_wrapper.py:119] From sample/contextual_generate_cli.py:122: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0823 12:51:54.504974 140496308524928 deprecation_wrapper.py:119] From /content/grover/lm/modeling.py:725: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0823 12:51:54.518433 140496308524928 deprecation_wrapper.py:119] From /content/grover/lm/modeling.py:490: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0823 12:51:54.607027 140496308524928 deprecation.py:323] From /content/grover/lm/modeling.py:143: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0823 12:52:05.206928 140496308524928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims` instead.\n",
            "W0823 12:52:11.244514 140496308524928 deprecation_wrapper.py:119] From sample/contextual_generate_cli.py:129: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0823 12:52:12.027129 140496308524928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Loaded model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9KrPjKkWp8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ae45c9a-a37d-4270-8823-2bac42f75e40"
      },
      "source": [
        "# newlines are  not supported well by Google Colab input so please using echo or printf to pipe your input in if you want to us enew lines\n",
        "# Just modify the text below to be what you want\n",
        "!printf \"American Family Insurance believes that a dream is the most valuable thing you can ever own.\\n\\n That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\\n\\n\" | PYTHONPATH=$(pwd) python3 sample/contextual_generate_cli_multiline.py -model_config_fn lm/configs/mega.json -samples 10 -model_ckpt models/mega/model.ckpt.800000"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0823 12:35:29.731748 140476373620608 deprecation_wrapper.py:119] From /content/grover/lm/optimization_adafactor.py:88: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0823 12:35:29.840907 140476373620608 deprecation_wrapper.py:119] From /content/grover/lm/modeling.py:87: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "\n",
            "~~\n",
            "batch size=1, max batch size=3, num chunks=1, batch size per chunk=1\n",
            "~~\n",
            "\n",
            "W0823 12:35:29.841809 140476373620608 deprecation_wrapper.py:119] From sample/contextual_generate_cli_multiline.py:121: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0823 12:35:29.842036 140476373620608 deprecation_wrapper.py:119] From sample/contextual_generate_cli_multiline.py:123: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-08-23 12:35:29.858368: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-23 12:35:29.858619: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ae3480 executing computations on platform Host. Devices:\n",
            "2019-08-23 12:35:29.858655: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-23 12:35:29.870822: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-23 12:35:29.976391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:35:29.976907: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f6300 executing computations on platform CUDA. Devices:\n",
            "2019-08-23 12:35:29.976942: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-23 12:35:29.977147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:35:29.977528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-23 12:35:29.982104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-23 12:35:29.994940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-23 12:35:30.006667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-23 12:35:30.014667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-23 12:35:30.025699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-23 12:35:30.041712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-23 12:35:30.069633: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-23 12:35:30.069816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:35:30.070292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:35:30.070743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-23 12:35:30.070811: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-23 12:35:30.071928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-23 12:35:30.071963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-23 12:35:30.071980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-23 12:35:30.072263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:35:30.072680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-23 12:35:30.073059: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-23 12:35:30.073114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0823 12:35:30.075217 140476373620608 deprecation_wrapper.py:119] From sample/contextual_generate_cli_multiline.py:124: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0823 12:35:30.131664 140476373620608 deprecation_wrapper.py:119] From /content/grover/lm/modeling.py:725: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0823 12:35:30.143962 140476373620608 deprecation_wrapper.py:119] From /content/grover/lm/modeling.py:490: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0823 12:35:30.237789 140476373620608 deprecation.py:323] From /content/grover/lm/modeling.py:143: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0823 12:35:40.988631 140476373620608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims` instead.\n",
            "W0823 12:35:47.090412 140476373620608 deprecation_wrapper.py:119] From sample/contextual_generate_cli_multiline.py:131: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0823 12:35:47.884565 140476373620608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Loaded model.\n",
            "Sample, 1  of  10\n",
            "2019-08-23 12:36:30.999609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Today, we are excited to open DreamBank.org, a mission similar to Facebook: to connect people with their dreams and stories of the reality of what we might someday be living.\n",
            "\n",
            "\n",
            "\n",
            "And to kick off the official opening of DreamBank.org, we're back with our latest video. After learning how to dream for yourself, it's easy to see why DreamBank.org is the place to be.\n",
            "\n",
            "\n",
            "\n",
            "***\n",
            "\n",
            "\n",
            "\n",
            "We love doing giveaways and we'll keep DreamBank.org up and running even if we need to invest a little cash to keep up with the demand for tech's latest, next-generation innovations.\n",
            "\n",
            "\n",
            "\n",
            "What do you get in return for your money? We'll give you amazing gifts, ranging from an amazing new Kindle to health solutions, like Alka-Seltzer. To make it even sweeter, we'll also give away a dream that you know you have.\n",
            "\n",
            "\n",
            "\n",
            "Wait. We can get you a dream? You asked for it. And you won't just get any dream. You'll get one of your dreams if you like using our technology to dream.\n",
            "\n",
            "\n",
            "\n",
            "Pick a time, date, and write a short note, and the device that you will receive will be your new DreamBank.com. Write your dream and see if it's accepted. DreamBank.com is more than just a dream, it's your chance to make your dream a reality.\n",
            "\n",
            "\n",
            "\n",
            "Enter, now.\n",
            "\n",
            "\n",
            "\n",
            "Love,\n",
            "\n",
            "\n",
            "\n",
            "Betsy and Amelia\n",
            "\n",
            "\n",
            "\n",
            "****\n",
            "\n",
            "\n",
            "\n",
            "DreamBank.org is now running a Giveaway sponsored by #MakeItLifest. Follow us on Instagram and Twitter to keep updated on the latest giveaway.\n",
            "\n",
            "\n",
            "\n",
            "Use promo code MWALSAYS1 when entering our giveaway.\n",
            "\n",
            "#MakeItLifest Exclusive Giveaway\n",
            "\n",
            "\n",
            "\n",
            "Want even more DreamBank.org fun? Find your perfect piece of dream land by registering. Join and update today.\n",
            "\n",
            "#MakeItLifest<|endoftext|>Newly appointed US National Security Adviser H.R. McMaster has reportedly told President Donald Trump that he doesn’t believe that fired FBI Director James Comey is a “good man.”\n",
            "\n",
            "McMaster reportedly also told Trump that he thinks Comey should have been fired after Trump revealed highly classified information to Russia in an Oval Office meeting in May.\n",
            "\n",
            "As originally reported by the Washington Post, McMaster took over the National Security Council on July 22 and replaced Michael Flynn as national security adviser.\n",
            "\n",
            "READ MORE: H.R. McMaster or Mike Flynn?\n",
            "\n",
            "McMaster’s first two days on the job as NSC chief of staff came under intense scrutiny, with CNN reporting that he “told Trump on Monday that Comey would not be his secretary of state if he were still in office.” He reportedly made those comments after his conversation with Trump on Friday, when Trump said he “hoped” that Comey “would finish the investigation quickly.”\n",
            "\n",
            "Trump told Russian Foreign Minister Sergey Lavrov and Ambassador Sergey Kislyak during a meeting in the Oval Office in May that he fired Comey because of the FBI’s probe into alleged collusion between the Trump campaign and Russia.\n",
            "\n",
            "One month later, the president admitted that he had fired Comey based on the Russia investigation.\n",
            "\n",
            "During his opening statement at his Senate confirmation hearing in January, McMaster denied that Trump was attempting to obstruct justice. Trump’s firing of Comey has since raised many questions and a formal request from Democrats for an independent commission to investigate the president’s meddling in the FBI’s investigation into Russia, and the 2016 presidential election.\n",
            "\n",
            "On Wednesday, McMaster denied that the Trump administration was seeking to interfere with the ongoing investigations.<|endoftext|>You must enter the characters with black color that stand out from the other characters\n",
            "\n",
            "Message: * A friend wanted you to see this item from WRAL.com: http://wr.al/xulA\n",
            "\n",
            "— State and federal authorities began searching for the last woman known to be missing in Wake County Wednesday morning after she was found alive two weeks after vanishing.\n",
            "\n",
            "Kimberly Bumstead, 34, was spotted early Wednesday morning by a local man, who noticed she appeared to be walking in the woods just north of her Richland Township home about 1:30 a.m.\n",
            "\n",
            "North Carolina State Patrol troopers and agents from the FBI, U.S. Fish and Wildlife Service and local authorities were investigating whether she had been involved in any crime.\n",
            "\n",
            "In the early hours of Jan. 20, Bumstead left her home to go to a party and never returned. She was reported missing on Jan. 26 and was considered endangered at the time, officials said.\n",
            "\n",
            "\"She's absolutely vital to the investigation,\" said\n",
            "Sample, 2  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "About DreamBank\n",
            "\n",
            "DreamBank is your space to explore and learn more about the dreams you have and to share your dreams with others.\n",
            "\n",
            "\n",
            "\n",
            "After years of searching for an ideal opportunity to share your dreams with others, we found a great one at Central Baptist Church in Ashburn, Virginia.\n",
            "\n",
            "\n",
            "\n",
            "Central Baptist began the dream project with the community in mind. Since 2009, DreamBank has been growing and building a community space that allows people to express and share their dreams.\n",
            "\n",
            "\n",
            "\n",
            "One of the areas DreamBank is expanding is online. We have been very surprised to see the positive response we have had to our platform and within the last year we have grown from a one-man project to nearly 50 people or individuals from around the country each day who participate in DreamBank and have shared their dreams with thousands of strangers.\n",
            "\n",
            "\n",
            "\n",
            "With 30 employees on staff at DreamBank and another 17 people helping us out with other DreamBank initiatives, we are very focused on the goal of making dream-sharing a very easy, rewarding way to share your dreams with the people you love and with the people in the world that love you.<|endoftext|>MUMBAI: Catholic clergyman Bhagwan Shree Nath may be floating an online platform to promote religious rights of Catholics, but the fear is that for Mumbaikars it might only serve to alienate them.Catholic priests generally frown upon advertising in such spaces because of their association with the organization known for child abuse scandal.Even though the priest has written to Union health minister JP Nadda asking him to heed the concerns of clergymen, the motive to promote the interest of minorities runs so deep that many insist that such advertisements are a waste of time.“There was some temple going advertisement in the papers and the priest complained,” said a senior priest of an unidentified temple in MIDC , adding that priests had not taken even a hint of the existence of a website of Shree Nath. “And then the priest was told to contact the website manager to get in touch with them,” he said.Pressed for his response, the priest, who refuses to be named, said, “I’m in favour of all religions in India, but I can’t see how promoting any religion online is any different from how Iwas pressured when I was detained by the Police due to a complaint.”Mumbaikars are not accepting the services of priests at all because of their connection with the Archdiocese of Mumbai. But priests feel that if they suffer under the online advertisement, it can be a useful tool to educate people. “We are trying to move on to communicating with people on more issues such as health and education. I understand it is easy to discredit us,” said Padrajesh Puri, the president of Christian Conference of India , the apex body of Catholic Churches in India.He stressed that the priests should refrain from going to print media and TV channels or talk on social media. “We have to spend so much time meeting people in various forms and we are finding it is better to leave this online. All this has to stop,” he said.The Church in Mumbai has not issued a ruling, but it is widely known that any permission obtained from the archdiocese prior to sending out any communication must be followed. In cases of advertisements like Shree Nath’s, it is understood that permission from the archdiocese and its legal department is necessary.No information available on the website regarding what is the commission for the advertisement. The civic body has put up details on the website, saying that the advertisements should not be excessive and be designed in a professional way with proper graphics.This is the first time in the history of the city that advertisements like Shree Nath’s are being issued at such a large scale, so as to showcase the institutions of different faiths. The advertisements also constitute a part of the initiatives by the government to portray the city in a balanced manner. The home ministry is said to have written to the priests to issue advertisements, something which the council of dioceses in the country has opposed in the past. Shree Nath had approached the Christ Church in Sewri, Ghatkopar, to launch a website on the same lines after meeting Nadda in Delhi.<|endoftext|>Iran’s embassy in Ottawa is expecting more than 10,000 people to attend Friday’s protest outside the embassy and consulate.\n",
            "\n",
            "The gathering was called by the anti-West, often anti-American, group United Against Nuclear Iran.\n",
            "\n",
            "“Demonstrations are expected to be held outside the embassies of the United States and Israel, and also other Western nations including the European Union,” according to the Associated Press, which provided news from Tehran on\n",
            "Sample, 3  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Whether it's visiting with others who have achieved the dreams we share, or sharing our own dreams with those who share the same passions, DreamBank is for everyone. If you happen to meet a dreamer in your travels, Share your dreams.\n",
            "\n",
            "\n",
            "\n",
            "We are excited to announce the addition of New York City. While previous DreamBank locations in Hawaii, Las Vegas, Colorado Springs, and Houston have been a highlight, now you can see DreamBank firsthand in New York City.\n",
            "\n",
            "\n",
            "\n",
            "DreamBank is a social service that provides a safe, casual space where people can share their dreams. Whether it's pursuing their college dreams, joining a professional athlete's \"Dream Team\", pursuing a new hobby, or even starting a retirement plan, DreamBank gives you the opportunity to share your journey with others.\n",
            "\n",
            "\n",
            "\n",
            "Connect with us on Facebook, Twitter, Pinterest, Google+, Instagram, and Pinterest using #dncfvgobank.\n",
            "\n",
            "\n",
            "\n",
            "<|endoftext|>Is a book on your mind? Wouldn’t you like to take a look?\n",
            "\n",
            "We’ve searched our databases to find just the right book for you, the reader. We’ve scoured libraries to find a trove of books that you’ll love to possess.\n",
            "\n",
            "Need suggestions for books that you can read in order to set you on the path to becoming a more effective citizen or to help you gain an understanding of the world?\n",
            "\n",
            "We’ve searched libraries across the country, reading a variety of titles for inspirational titles.\n",
            "\n",
            "We’ve carefully read the titles so that we can provide you with the list of books you can enjoy. Each of the suggestions contained in our list represents a completely unique way to spend an afternoon reading.\n",
            "\n",
            "Our reading recommendations are based on specific topics. You should use this list to get you on the path to follow, and once you’ve joined the band, make sure you enjoy it.\n",
            "\n",
            "We will be regularly updating our books recommendations, as more titles become available. Thank you for reading and help us to help you enjoy, learn, and grow as a person.<|endoftext|>Image caption Michelle Doherty was one of 10 people arrested on suspicion of financial offences\n",
            "\n",
            "A former chief constable of the Royal Ulster Constabulary (RUC) has been jailed for 10 years for stealing millions of pounds from the ex-Tánaiste and ex-home secretary Jack Straw and MPs.\n",
            "\n",
            "Michelle Doherty, who was a detective constable, arranged for more than £17m worth of cash to be dispensed from former homes owned by Ms Doherty as her husband Robert Doherty was transferred to the RUC.\n",
            "\n",
            "Defence lawyers said that Doherty, 48, knew the money was stolen.\n",
            "\n",
            "The cash was said to have come from funds that could have been used to pay RUC bills.\n",
            "\n",
            "Doherty pleaded guilty to money laundering and the spending of fraudulently obtained cash, as well as for damaging her husband's reputation.\n",
            "\n",
            "At Belfast Crown Court, Doherty was also ordered to pay £2.75m in compensation to the three politicians.\n",
            "\n",
            "The court heard how she had been the first to inform the former politicians of the scam in the spring of 2011, informing their wives, who in turn informed Ms Doherty's husband.\n",
            "\n",
            "A sting operation involving detectives posing as fraudsters was followed by a High Court hearing last month, which heard she told her husband how much money she had managed to \"heap\" on his property portfolio.\n",
            "\n",
            "Doherty was arrested after the hearing and handed over to the police.\n",
            "\n",
            "The money in question included money taken from the couple's home at Applecross, Co Down.\n",
            "\n",
            "It was claimed in court that Robert Doherty returned from an RUC training course to find his home empty and thousands of pounds being shifted in the house.\n",
            "\n",
            "Doherty returned and noticed her husband's front door had been padlocked and a sign saying: \"For the safety of Mr Doherty, please do not approach Mr Doherty.\"\n",
            "\n",
            "Championships\n",
            "\n",
            "She said that she was trying to advise her husband that the police were after him for another investigation he had nothing to do with.\n",
            "\n",
            "Ms Doherty argued to the police that Mr Doherty was not allowed to put a number on his home because the RUC were interested in the rumoured sums of money and she was trying to give her husband advice in order to avoid prosecution.\n",
            "\n",
            "She denied the car park outside her home was used as a place for banks to deposit cash she had been instructed to give the RUC.\n",
            "\n",
            "There were allegations by Doherty's lawyers that the money that was taken from Ms Doherty's property was then used to pay off RUC debts for her husband.\n",
            "\n",
            "Jailing Doherty, judge Lord\n",
            "Sample, 4  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Great things are possible when dreams can come true. Right now, there are just a few of those great things out there.\n",
            "\n",
            "These dreams are big and they're beautiful. Dreams are changing lives, making a difference, changing what people talk about and most importantly, changing what is possible.\n",
            "\n",
            "Please join us by sharing your dream with us.\n",
            "\n",
            "We already get a lot of dream participation -- ask us about starting a dream today.<|endoftext|>Image caption Mark Duggan killed officer Keith Palmer with a gun held in his right hand\n",
            "\n",
            "The UK's most senior officer investigating the police shooting of Mark Duggan is to be dismissed, the home secretary has said.\n",
            "\n",
            "The Metropolitan Police Commissioner Sir Bernard Hogan-Howe was told he had been placed in command of Operation Trident, which covers the Tottenham area of north London.\n",
            "\n",
            "Assistant Commissioner Bob Quick will take over the role as head of homicide and serious crime.\n",
            "\n",
            "Police groups have attacked the \"ignorance\" of the Met Police commissioner on lessons of race.\n",
            "\n",
            "Sir Bernard's decision followed a response to a letter from Prime Minister Theresa May asking for his \"urgent\" resignation.\n",
            "\n",
            "Mr Quick was appointed Met commissioner in June 2010 following his resignation from New Scotland Yard as the head of the Specialist Operations Directorate.\n",
            "\n",
            "The following month, then-London Mayor Boris Johnson said no officer from his administration would go to G4S in any future role.\n",
            "\n",
            "'Contrasting perspective'\n",
            "\n",
            "Sir Bernard has been described as having his \"personality and experience rather than his worth as head of London's own special operations team\" in the letter by Mrs May, who told him: \"The IPCC (Independent Police Complaints Commission) has provided clear evidence that there has been a failure to obtain sufficient forensic evidence in respect of the fatal shooting of Mark Duggan in August 2011.\n",
            "\n",
            "\"In the light of this, your departure as police commissioner is justified and I want to thank you for your service.\"\n",
            "\n",
            "She added that Assistant Commissioner Bob Quick would become acting Metropolitan Police Commissioner.\n",
            "\n",
            "Home Secretary Theresa May told journalists in Downing Street that the Met investigation was due to produce \"a narrative account of the events leading up to the shooting, as well as the process that led to the death\".\n",
            "\n",
            "She said the culture of mistrust, and \"the danger that new and misleading evidence is picked up and put into the wider investigation\", needed to be addressed.\n",
            "\n",
            "Media playback is unsupported on your device Media caption Sir Bernard Hogan-Howe told the BBC that he wished to address tensions that \"have been deep within the community in Tottenham\"\n",
            "\n",
            "It was hoped that Ms Duggan's estate would be involved in \"deliberate and objective dialogue\" about the investigation, she added.\n",
            "\n",
            "Shadow Home Secretary Yvette Cooper said it was clear \"as a result of the question of culture and policing\", the IPCC \"needed to properly examine this matter\" as well as questions surrounding \"the political interference in this police investigation\".\n",
            "\n",
            "She said the inquiry into Mr Duggan was being \"worried about and has yet to produce\" a final result as to whether \"there has been a cover-up\".\n",
            "\n",
            "\"It would be a good thing if they came to a judgment and began to gather evidence - that is the work of an independent and impartial inquiry, and that does, frankly, need to happen,\" Ms Cooper said.\n",
            "\n",
            "Ms Cooper said her party would be contesting the London mayoral election in May 2016.\n",
            "\n",
            "Mark Duggan, 31, died after he was shot by police in Tottenham, north London, on 4 August 2011.\n",
            "\n",
            "His family said officers had been \"aiming guns at him\" as they arrested a number of other people.<|endoftext|>For those readers who thought that GeForce Experience was the only way to control your GeForce GPU, NVIDIA has today announced the release of GeForce Experience Lite, a new software tool which will allow developers to implement new features from the company's massive catalogue of titles.\n",
            "\n",
            "As you might have guessed, GeForce Experience Lite is expected to work with both DirectX 11 and DirectX 12 drivers. You will be able to run any game and tweak a number of customizations, which should, ultimately, give developers a significant advantage in terms of the game's performance and image quality.\n",
            "\n",
            "Developers should get the update, which will be free of charge, as soon as NVIDIA releases the new drivers.\n",
            "\n",
            "In terms of content, you're looking at around four hundred titles so far.<|endoftext|>FILE PHOTO: The logo of HTC is pictured on an electronic shop in Tokyo February 3, 2014. REUTERS/Yuya Shino/File Photo\n",
            "\n",
            "(Reuters) - HTC Corp was the most popular Android smartphone maker in China at the end of 2016, according to analyst analysis from IDC Inc.\n",
            "\n",
            "The Taiwan-\n",
            "Sample, 5  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "We believe that anyone can start up a dream. And we want to provide helpful guidelines for companies seeking to create a new lifestyle.\n",
            "\n",
            "\n",
            "\n",
            "Inspired by the artist Brandon Stanton, we call our community frontbenches. Any startup can go see the frontbench at DreamBank and start a dream.\n",
            "\n",
            "\n",
            "\n",
            "So what are you waiting for? Join us at DreamBank to start your own dream start-up.<|endoftext|>A legal loophole that lets some officials buy drugs at public expense, as long as they admit to using them, may be open to abuse.\n",
            "\n",
            "Solicitor-General Stephen Donaghue said he would send the proposal to Cabinet for approval after a proposal to relax the rules was sent to him by Finance Minister Michael Noonan.\n",
            "\n",
            "The proposal would allow ministers to spend money on those with medical or psychological conditions, including depression, who cannot access health services.\n",
            "\n",
            "Read More: Two TDs arrested after home bought by prison guard\n",
            "\n",
            "Mr Donaghue said he did not think many ministers would want to accept the possibility of having to describe themselves as addicts or suffering from severe depression.\n",
            "\n",
            "But he acknowledged that many existing rules on buying drugs from local bordellos of dubious repute may need review.\n",
            "\n",
            "Mr Donaghue said “there is an obvious concern about such schemes. The question is ‘can these schemes be managed so that, for example, those who genuinely need the drug but are prevented from getting it elsewhere by the prohibition and criminalisation of the drug trade would benefit from these schemes’.”\n",
            "\n",
            "In response to a query from this newspaper, Mr Noonan said he was interested in the proposal, but added: “I am not aware of any departmental minister having access to drugs other than in rare and exceptional circumstances.”\n",
            "\n",
            "Read More: Decline in number of Irish in prison linked to drugs\n",
            "\n",
            "\n",
            "\n",
            "Mr Noonan said there were two main criteria when deciding whether to fund these schemes: if the recipient genuinely needed the drug, and if they could self-refer or pay out of pocket for the drug.\n",
            "\n",
            "A legislative change on this subject would introduce some degree of transparency, he said.\n",
            "\n",
            "The proposal, which would not open the door to dossiers and detailed information on past drug-taking habits, was sent to Mr Noonan at the end of last year.<|endoftext|>If reports are correct, Peter Sagan will lose the CIRC Specialized-lululemon-Vittoria Tour team at the end of the season in a parting of the ways following this month’s stages of the Giro d’Italia. Related Articles Hushovd awarded first WorldTour CIRC prize\n",
            "\n",
            "Analysis: The CIRC report on the UCI reform process\n",
            "\n",
            "“The timing of the end of the season is unlikely to be announced. At this stage, I cannot confirm anything. However, it will most likely be at the end of the Giro d’Italia,\" Specialized's Austrian boss, Eberhard Von Stuben, told Der Standard (in German).\n",
            "\n",
            "The CIRC report was released on Friday night to the public and on Monday, riders started the process of getting their contracts analyzed. According to the newspaper, some riders may not be retained by their teams at the end of the season as a result of the findings of the investigation.\n",
            "\n",
            "According to the leaked report, it will found that Armstrong took EPO, testosterone and Human Growth Hormone with the involvement of US Postal, Discovery Channel, Ice Sports, Ferrari, Dr. Michele Ferrari, Dr. Johan Bruyneel and Alberto Contador. The UCI voted to apply the rules that protect neither a team nor the riders from Lance Armstrong and the supplements he took.\n",
            "\n",
            "The seven riders who made the most headlines during the investigation have been banned from cycling for life and six other riders have been stripped of their titles after they were found to have cooperated with the American to gain advantages for their teams.\n",
            "\n",
            "The GC riders who were linked to Armstrong by CIRC Team Principal Johan Bruyneel - and who were rumoured to have had a relationship with Lance Armstrong - will not get protected as the UCI proposes to strip them of their titles. Instead, they will either be stripped completely, or fall back down to being enduros or time trial riders.\n",
            "\n",
            "Among the riders who will only have a reduced number of titles for 2014 will be David Millar, Alejandro Valverde, Bauke Mollema, Alberto Contador, Richard Virenque, Nicolas Roche, John Degenkolb, Brent Bookwalter, George Hincapie, Paul Voss, Ryder Hesjedal, Nibali, Giorgio Cecchini, Chris Horner, Michael Matthews\n",
            "Sample, 6  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Home: DreamBank\n",
            "\n",
            "Website: http://dreambank.com/\n",
            "\n",
            "About the Company:\n",
            "\n",
            "\"The Dream is the most valuable possession we all possess. . ..\" - Thomas Sowell, The Facts for the Mind\n",
            "\n",
            "Everybody wants to wake up to the fortune they envision, but dreams tend to endure far longer than our expectations. The DreamBank is the place to look for dreams that live on after your dream fades.\n",
            "\n",
            "\n",
            "\n",
            "DreamBank is a gathering place for dreamers to talk about and share their dreams with each other. The DreamBank was created as a community project to create a permanent place where dreams can be loved, shared, dreamt, and enjoyed.\n",
            "\n",
            "\n",
            "\n",
            "Learn more about the story behind The DreamBank: http://mydreambank.com/story/\n",
            "\n",
            "Find out more about Thomas Sowell at his website.\n",
            "\n",
            "Contact: obitc@freetbh.com\n",
            "\n",
            "<|endoftext|>The Department of Homeland Security (DHS) has opened a federal hate crime investigation into the beating of a Pakistani man on New York City’s subway by two Trump supporters because of the Muslim man’s beard.\n",
            "\n",
            "New York’s Daily News reports that a Trump supporter punched and kicked Rizwan Farook, a 32-year-old Pakistani American, on Saturday while yelling “Make America great again.” Farook spent nearly a month in the hospital after the attack, and has received orthopedic surgery and almost all of his teeth.\n",
            "\n",
            "Farook told ABC News that his attackers seemed like they were motivated by Trump’s recent travel ban as well as his rhetoric.\n",
            "\n",
            "“I didn’t wear a turban,” Farook said. “I wore a kurta — I think I did. But they thought I had a beard and I was wearing a turban.”\n",
            "\n",
            "Advertisement\n",
            "\n",
            "“I got attacked because of my facial hair,” Farook said. “I don’t blame Trump, but what he’s saying is making people angry.”\n",
            "\n",
            "Backlash against the men has fueled hate crimes against Muslims.\n",
            "\n",
            "Farook’s brother – Muhammad – wrote a long Facebook post asking why the two attacked him, as Islam has strict rules about beards.\n",
            "\n",
            "“When they stop talking all of this will be over and a lesson to all,” Muhammad Farook wrote. “We can get along, support each other and live normal lives. There is a law, one called God. May he help us all and may Allah protect us all.”\n",
            "\n",
            "A neighbor of Farook’s, Shawna Wheeler, was interviewed on Fox News Monday morning, telling the network that Rizwan had only been visiting friends and family for the past year, and did not attend mosque regularly.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "“I saw him with his brother being alone one day in the street and he was attacking his brother with a baseball bat. I don’t know why,” Wheeler said.\n",
            "\n",
            "Read more at the Daily News.<|endoftext|>CHICAGO (Reuters) - McDonald’s Corp is teaming up with three Chicago hospitals on a partnership that will allow patients there with heart problems to order a meal with fries.\n",
            "\n",
            "“We have seen a pretty strong positive response from the public on the viral video. We wanted to expand our opportunity to bring our customers customized-menu experiences like McDonald’s Healthy Meals to Chicago,” said Guy Kewney, Senior Vice President of Global Diversity at McDonald’s, which confirmed the deal on Friday.\n",
            "\n",
            "Ad-supported job videos were phased out at McDonald’s last year and the last McDonald’s TV ad program, which portrayed unemployed workers as needing to “make McDonald’s Happy Meal dreams come true,” came to an end in April 2014.\n",
            "\n",
            "The McNugget sandwiches with potatoes are new. McDonald’s said the menu item has proven popular in other parts of the country but it was difficult to offer patients at local hospitals such unique items, and the burgers sold were old and tough to source.\n",
            "\n",
            "In the Chicago partnership, the burgers are served with fries. Patients visiting Jackson Memorial Hospital will be able to get a “Real McNuggets” burger at lunchtime. The other two hospitals will offer patients with cardiovascular conditions a “McWraps” burger at dinner.\n",
            "\n",
            "Other restaurants worldwide, including Whole Foods Market Inc, have partnered with hospitals for heart-related visits, such as daily home delivery from an app called HubSpot. Patients are chosen from an initial list based on their medical status, diet and lifestyle.\n",
            "\n",
            "McDonald\n",
            "Sample, 7  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "The DreamBank space offers a safe, welcoming environment where you can come and show off your best in your dreams, from computer games to big box store items and more.\n",
            "\n",
            "The DreamBank space provides the ultimate community validation of your dreams. Through local badge transactions and rewards, every activity that happens inside the DreamBank space is countable and tracked. Not only that, but the activity in the DreamBank space gets an automatic bonus based on the total number of activities logged in the space.\n",
            "\n",
            "The DreamBank space allows you to show off what makes you stand out. You may do just that by showcasing your 5K runs, selfies with your cats, or big-ticket purchases through top sellers. If you have purchased items through Abundance 360, you can show off your DreamBank badge by taking a picture of your purchase and submitting it to us.\n",
            "\n",
            "DreamBank connects with your physical life to authenticate your dreams. You are instantly able to discover new online competition competitions related to your dreams. You can even record your dreams directly on the DreamBank space.\n",
            "\n",
            "Whatever your dreams are, they are an important part of your life. The DreamBank space is designed to celebrate and encourage your dreams. Whether you choose to add your DreamBank badge on an external platform (like Abundance 360) or just manually add it to your DreamBank space, you are in a group of fellow dreammakers.\n",
            "\n",
            "Create a DreamBank badge badge on any device and you'll instantly know whether your dream is being validated, and you can log in to our DreamBank tracking site to help improve your dream economy. The same way you are rewarded for your activity on DreamBank, your DreamBank activity will earn you points. Over time, you'll earn more points.\n",
            "\n",
            "\n",
            "\n",
            "MARKETING: http://www.dreambank.org<|endoftext|>This Sunday, October 28th, this hilarious, seven minute animated short will air exclusively on Family Guy.\n",
            "\n",
            "It’s all about a man with diarrhea pants who hands out diarists all over town. It’s the funniest shit you’ll see all week and make America great again.\n",
            "\n",
            "Learn more about the short here.\n",
            "\n",
            "Tommy Carcetti is a superstar in the field of medicine. He’s SARS-resistant, rubs the government with his warts, and works on private comatose patients. But Tommy was first exposed to his sick career when he traveled from a SARS vaccine clinic in China to the Myle Leopold psychiatric hospital. Tom traveled through a hole in the wall and stepped right into a clinic run by the Mad Poet Sister. The sister knew Tommy would have to feed her, and had him take a bandaid off his forearm so she could scratch her penultimate patient’s bloated asshole.\n",
            "\n",
            "What follows is a terrible tale of payola corruption, health care hunger, and bureaucracies. The Mad Poet Sister is finally throttled by the former surgeon specializing in SARS, who had recently moved on from being the head of SARS research to the Chairman of the Organization of Suicide Prevention. The Mad Poet Sister exclaims with wide eyes, “It’s all… wrong… and yet I’m afraid this is probably still a great day for me.”\n",
            "\n",
            "* * *\n",
            "\n",
            "Historically, Family Guy has been a fundamental driver of social discourse in America by reflecting and sharing day-to-day humor, much of which we've all learned from. But this particular episode has launched a rather large conversation, racking up more than 230,000 hits in just two days on Buzzfeed.com:\n",
            "\n",
            "[Anny] Becks: “I hope Tim Tebow emerges from the struggle and thrives on the strength of the shame society built for him,” writes BoingBoing.com.\n",
            "\n",
            "Wes: “Personally, I think that the misery of the America a Tim Tebow would represent is pretty easy to illustrate,” writes a testy John Ydstie at TheFool.com.\n",
            "\n",
            "We’re not sure what to make of this conversation, but we do know that their collective rage is an awesome inroad to digging deeper and coming up with a constructive answer to how to solve America’s primary social problem.\n",
            "\n",
            "So if you're an American, you should consider yourself warned that you've put all your hopes and dreams on the shoulders of an otherwise handsome man who hands out a medication called \"Diarrhea Pants.\" Call it \"The Miracle Diarrhea Pants,\" or \"Bozo's Best Diarrhea Pants,\" or, if you must, go call my boss and start a divorce suit.\n",
            "\n",
            "I suppose you could argue that, if you're\n",
            "Sample, 8  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Introducing: DreamBank in the News\n",
            "\n",
            "\n",
            "\n",
            "Good News for Dreamers:\n",
            "\n",
            "\n",
            "\n",
            "The Headline-Making Dream Casino Franchise in Reno (First Resort Hotel in North America)\n",
            "\n",
            "The DreamBank Franchise in Reno, Nev. is set to open its doors in the first week of May 2017.\n",
            "\n",
            "\n",
            "\n",
            "For more than 30 years, James Wolfram & Sons has been building holiday housing for families in a wide variety of locations throughout the world. And we're excited to be part of the new DreamBank in Reno, Nev. (Photo courtesy of James Wolfram & Sons.)\n",
            "\n",
            "\n",
            "\n",
            "Employees are excited about the development as well. “This is a great location for our employees to call home. It will be an enhancement to our well-performing business.” -Chris Mitchell, Fresno, Calif.\n",
            "\n",
            "Affordable Loans to Help You Grow Your Dreams\n",
            "\n",
            "\n",
            "\n",
            "James Wolfram & Sons® is an accredited and successful payday lender.\n",
            "\n",
            "\n",
            "\n",
            "Every family should have the opportunity to pursue their dreams. James Wolfram & Sons® works closely with businesses to identify family-friendly lending opportunities for its customers. Family-friendly lending opportunities often provide high-interest, low-payback loans. These loans can be used by men and women who are parents, single parents, or those hoping to re-enter the workforce.\n",
            "\n",
            "\n",
            "\n",
            "These affordable loan products help families responsibly get started with financial literacy education. In many cases, a payday loan is necessary to help a person pay off existing debts such as a car loan or a credit card and start a new career.\n",
            "\n",
            "\n",
            "\n",
            "James Wolfram & Sons® applies a lending philosophy to all of its business divisions. The company does not allow payday loans until customers have received some financial education. And after the basic financial education is complete, we provide a loan rate and a link to a national network of licensed lenders.\n",
            "\n",
            "\n",
            "\n",
            "Low-cost credit, no interest, a lien placed against your home and affordable advance payments are all part of the James Wolfram & Sons® formula for success. Family friendly lending is an important component to the business.\n",
            "\n",
            "Coming Soon:\n",
            "\n",
            "\n",
            "\n",
            "Keep Reading\n",
            "\n",
            "The Source to Nourish and Abundance\n",
            "\n",
            "\n",
            "\n",
            "Some of the top American Family Insurance executives have always believed in following their passion. That was their motivation to build American Family Insurance® on the Earth.\n",
            "\n",
            "\n",
            "\n",
            "In 1986, Daniel Chapman was charged with building American Family Insurance from a start-up that sold Liberty Loan Pro High-Finance insurance to individuals and businesses. He began by eliminating all the variables and obtained a one-of-a-kind name. Daniel was excited to bring us to you. The business turned out to be a financial miracle.\n",
            "\n",
            "\n",
            "\n",
            "Now, with the strategic partnership of American Family Insurance®, we are doubling down and building, from a capital base of only $300 million, a privately held entity that will be the first and most innovative bank in the world.\n",
            "\n",
            "\n",
            "\n",
            "Upon that day, The Source to Nourish and Abundance® will move from 100% publicly traded shares to a privately held Fortune 500 company that will become The Source to Nourish and Abundance®, the world's first, most comprehensive bank. We will be the best bank in the world.\n",
            "\n",
            "\n",
            "\n",
            "And, it all begins this April 2017. See you at DreamBank, starting April 1st.<|endoftext|>Iraqi national guard recruits test their semi-automatic rifles during a training session in Baghdad's Basra August 7, 2008. REUTERS/Thaier Al-Sudani\n",
            "\n",
            "BAGHDAD (Reuters) - Iraq and Iran, accused of failing to prevent a pipeline attack by Islamic State militants that killed at least 42 people in northern Iraq last month, discussed cooperation during a telephone call, Iraqi Prime Minister Nuri al-Maliki said on Wednesday.\n",
            "\n",
            "“During the conversation between the Iraqi and Iranian officials, it was decided to improve and cooperate in many fields in order to be able to achieve the goals of the alliance and to share the services and efforts of the two countries,” Maliki told a news conference.\n",
            "\n",
            "Iran is a loyal ally of Baghdad, a U.S. ally since the Iraq war of 2003. The United States and Iran oppose Islamic State, a Sunni Muslim group that controls parts of Iraq and Syria.<|endoftext|>MILWAUKEE (Reuters) - Wisconsin’s Republican governor signed the first bill into law in state history requiring voters to present photo identification as well as a birth certificate or other identity papers to cast ballots.\n",
            "\n",
            "U.S. Republican presidential candidate Mitt Romney addresses thousands of enthusiastic supporters at rallies in Bonita Springs, Florida July 21, 2012. REUTERS/Kevin Lamarque\n",
            "\n",
            "The measure will go into effect on November 7, and people\n",
            "Sample, 9  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Click here to read our blog post about DreamBank.\n",
            "\n",
            "\n",
            "\n",
            "Register for DreamBank.\n",
            "\n",
            "\n",
            "\n",
            "We encourage anyone interested in joining DreamBank to take part in our next Dream Wall Challenge.\n",
            "\n",
            "\n",
            "\n",
            "This year's Dream Wall Challenge is tied to St. Paul's Centennial Celebration on May 23, 2015. We invite everyone in the Twin Cities to join in on the celebration by creating a dream of their own.\n",
            "\n",
            "\n",
            "\n",
            "What is Dream Wall Challenge?\n",
            "\n",
            "\n",
            "\n",
            "Dream Wall Challenge is a mini-festival that launches on Saturday, April 30, in addition to the main festival on May 23, and will run through June 15, 2015. We invite everyone to create a new, unique dream for your community that will be displayed along the Centennial Avenue corridor between Lake Street and Snelling Avenue.\n",
            "\n",
            "How can I participate?\n",
            "\n",
            "\n",
            "\n",
            "Winners will be chosen from entries using a simple, fun-filled, DreamWall Puzzle to discover the perfect dream for their community. See a sample of last year's entries here.\n",
            "\n",
            "\n",
            "\n",
            "How do I enter the competition?\n",
            "\n",
            "\n",
            "\n",
            "Create your dream and provide a clear, concise description of it and a short list of three names. See details about the DreamWall Puzzle.\n",
            "\n",
            "\n",
            "\n",
            "What materials will be used?\n",
            "\n",
            "\n",
            "\n",
            "Letterpress crafts, calligraphy, pastel, digital print, acrylic, photo paper, markers, pencils, colored pencils, different sizes of paper, rough draft of your dream, art supplies, stationary, business cards, anything else you can think of, stickers, magnets, you name it.<|endoftext|>In the end, there are only two clear answers to this question:\n",
            "\n",
            "1. Whether you like the subject or not, the historian and what he calls “think-tank warriors” are indeed in favor of a state that operates as a trustee of resources while offering deep tax cuts to corporations and the rich. Which is why, in the very moment they are debating whether Trump’s ideas are legitimate or not, their own imagination is producing policy proposals. The think-tank champions of reducing taxes while giving away free stuff are then further making the case that Trump is a champion of tax cutting and flat tax and minimal regulation in the economy. All of this is driven by the desire to sow chaos.\n",
            "\n",
            "2. Ultimately, the question is how likely this chaos is to succeed. The more the New York Times reports on how mean the bureaucracy in Washington is being, the less likely the presidency will implement the different parts of its agenda. Anyone who wants results has to be rooting for Trump to finally be able to stand for what he has to say. How and when can Republicans actually enact their regressive agenda on one hand, and what could happen if they try to turn the corner and do what Trump wants on the other? The mess of dueling sources of chaos does not help here.\n",
            "\n",
            "<|endoftext|>For several years, I enjoyed Modernist Cuisine: A Roasting Blog. Many of the cooks in the video comments below have asked me how I keep my little clams in the shell. Well, I made them several times before I realized the truth. Cook them at high heat until the flavor and shape have cooked out the shells and will not work. OK, that's enough to disappoint your friends, right? My wonderful, small-clawed friends. If you own two baby clams and would like to come over for a play date, I would love to show you how I do it. Just let me know and I will prepare you one lovely lobster au poivre.\n",
            "\n",
            "MAYME: This recipe is an integral part of our brunch (this is what we have for food for lunch) and quinoa.\n",
            "\n",
            "JASON: Well, while I take the pleasure of the clams seriously, we're not sure whether or not I would consider posting this online. Please know that I have no grudge against Modernist Cuisine. I am an avid reader and love the photo and cooking features. This is the only reason I made this recipe and then posted it. I like to share my methods. Just so you know.\n",
            "\n",
            "MAYME: [Brain Hacks] I'll try to avoid reading through each comment and simply say, THANK YOU!!\n",
            "\n",
            "JASON: Thanks so much for sharing this with us. I hope you enjoy it. I'll make it this time and post it on July 1st.\n",
            "\n",
            "MAYME: :)\n",
            "\n",
            "JASON:<|endoftext|>Donald Trump’s election as president sent markets into panic mode, but financial institutions aren’t impressed with the president-elect’s chief strategist, Steve Bannon.\n",
            "\n",
            "In a rally on Monday, the billionaire investor Carl Icahn accused Bannon of lacking a background in business. “He knows nothing about\n",
            "Sample, 10  of  10\n",
            "American Family Insurance believes that a dream is the most valuable thing you can ever own.\n",
            "\n",
            " That's why we created DreamBank, a community space dedicated to the pursuit of dreams.\n",
            "\n",
            "\n",
            "\n",
            "Become part of the world's first dream bank. Share your dreams and goals with everyone you know. Feel the love of your community as you learn about the positive impact of one's dreams on the world. DreamBank is part reward card, part community living tool, and part dream theater.\n",
            "\n",
            "\n",
            "\n",
            "Already an AFI member? Shop a dream or receive a special offer. Let us know what dreams you want to pursue by filling out the dream submission form on the website.\n",
            "\n",
            "\n",
            "\n",
            "Please use only your real name and email address. You will receive a notification when your DreamBank entry has been approved and displayed in DreamBank.\n",
            "\n",
            "\n",
            "\n",
            "<|endoftext|>Phandroid, the web of software developers, took to the streets to gauge public sentiment on the release of the Nexus 4. Readers were surveyed to see what we can expect from the new device in the coming months.\n",
            "\n",
            "\n",
            "\n",
            "Overall, impressions were positive. Saying that the Nexus 4 is a \"thrilling upgrade\" is an understatement. We recently finished a hard run down of many of the apps that accompany the new phone, and they all surprised us with their functionality and usefulness. We'll go over each of them and what they offer.\n",
            "\n",
            "\n",
            "\n",
            "Android 4.2 promises to be the new \"golden age\" of Android for the platform, bringing several notable improvements and updates. One of the most exciting of these is a new homescreen panel with widgets, access to Wi-Fi and Bluetooth, and everything else that typically sits on the home screen menu.\n",
            "\n",
            "\n",
            "\n",
            "We were also very impressed with the device's battery life -- we're averaging over 10 hours of streaming video, 4-hour battery life between charges, and an average 0.5-hour \"turbo\" mode. Considering that Android is geared towards an average of eight hours of usage, the extra time is very impressive, and demonstrates Motorola's efforts to emulate some of Apple's strategy.\n",
            "\n",
            "\n",
            "\n",
            "Future updates to Android, especially the Motorola devices, will be one of the best ways to put some of those promises into practice. It's less clear whether an Android 2.3.3 update is coming with the new Nexus device. After all, Google remains tight-lipped on many of its Nexus devices. We'd bet on an early Q4 release in either Q4 or Q1 of 2012, assuming no big bugs come out in the meantime.\n",
            "\n",
            "Previous Next 1 of 4<|endoftext|>He said he has not committed the crime and the woman had given a lift home to a taxi driver. She was arrested and later released.\n",
            "\n",
            "A 30-year-old woman was raped in Mumbai in broad daylight by a couple of men on Friday, and police are questioning one of them over alleged links to a sex racket in the city.The woman had approached the Kalaburagi police station around 1 pm on Friday in distress, claiming she had been raped by two men at a park near Fort Road. The woman said that the first one had allegedly taken her home to his house, while the second gave her a lift back to the park.But the incident took a more sinister turn after the woman shared her experience on Facebook.Police said the driver of the cab had admitted to “giving the passenger the lift.” He is a resident of Thane but moved to Kalaburagi last year. When questioned about his said whereabouts, the driver said that he was in the US for the next two weeks. The woman did not share his exact location with police.Police said the second man had been arrested as well, after the woman recounted her ordeal to the police. The woman has identified him as Balvinder Singh, a reputed Mumbai cab driver. A team of police has been dispatched to his residence and will take him into custody as well.The woman said she had been “flirted” by the two men, and an argument took place before they raped her. The two men have denied the allegations. The next day, police received a complaint from another woman who had been picked up by the same duo. She too narrated her ordeal in a Facebook post that attracted angry comments. Police on Monday arrested Balvinder Singh and a group of accused, including some women, in the alleged sex racket racket on charges of sex trafficking.A man who claims to be the “mastermind” of the sex racket and of having taken people to Mumbai to indulge in sex with them, Thane resident Balvinder Singh is being interrogated by police. He has taken Rs 20 lakh from at least 30 women in the alleged sex racket. The woman who gave the lift to the Mumbai rape suspects had also left behind a tape on her phone in which the suspect allegedly threatened her, cops said.The videos are at the Mumbai police forensic lab, investigators said. “We are questioning the driver of the taxi to find\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Z1V2j5XAZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}